{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae234cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import copy\n",
    "\n",
    "def save_jsonl(address,data,name):\n",
    "    f = open(os.path.join(address,name+'.jsonl'),'w',encoding = 'utf-8')\n",
    "    for i in tqdm(data):\n",
    "        f.write(json.dumps(i,ensure_ascii=False)+'\\n') # for korean\n",
    "\n",
    "def load_jsonl(path):\n",
    "    result = []\n",
    "    f = open(path,'r',encoding = 'utf-8')\n",
    "    for i in tqdm(f):\n",
    "        result.append(json.loads(i))\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce74c3",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613f0548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-17 08:50:30,907] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbacd0f80584cb882899b8defba1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", attn_implementation=\"flash_attention_2\", trust_remote_code=True, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a586e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8224a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_jsonl('./msmarco_samples.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbae657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passage_to_text(passage):\n",
    "    if passage['title']=='-':\n",
    "        return passage['text']\n",
    "    else:\n",
    "        return passage['title']+' '+passage['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbca4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_segment_relevance_tagging(tokenizer, passage, question, tokenize=False):\n",
    "    user_message = f\"\"\"Please identify the given passage is related to the given question.\n",
    "    Make answer just TRUE or FALSE.\n",
    "    JUST answer the question.\n",
    "    DO NOT say the explanation. \n",
    "    \n",
    "    Provide your response as follows:\n",
    "    Answer: (TRUE or FALSE)\n",
    "\n",
    "    Now here are the passage and question.\n",
    "    \n",
    "    Passage : {passage}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    messages = [\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=tokenize, \n",
    "            add_generation_prompt=True\n",
    "            )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810870c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(relevance):\n",
    "    relevance = relevance.split('\\n')[0].strip()\n",
    "    if 'false' in relevance.lower():\n",
    "        return False\n",
    "    elif 'True' in relevance.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3273cf",
   "metadata": {},
   "source": [
    "# data set explanation\n",
    "- dataset\n",
    "    - question_id : question id of the data sample in msmarco\n",
    "    - positive_passage_segment : gold passage segment\n",
    "    - retrieved_passages : retrieved passages by the bm25 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff236a",
   "metadata": {},
   "source": [
    "# Knowledge Segment Relevance Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d37541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "TRUE\n",
      "\n",
      "The passage does provide information on roasting asparagus in the oven and includes a roasting time of 15 to 20\n",
      "TRUE\n",
      "FALSE\n",
      "Answer: FALSE\n",
      "\n",
      "The passage provides information on how asparagus can be cooked and the importance of cooking time, but it does not give a specific\n",
      "TRUE\n",
      "\n",
      "The passage mentions that the roasting time for asparagus is affected by oven temperature, and at 500 degrees, it\n",
      "Answer: FALSE\n",
      "\n",
      "The passage provides a range of roasting times for asparagus depending on the oven temperature, but it does not give a specific\n",
      "False\n",
      "False\n",
      "False. The passage does not provide information on how long to roast asparagus.\n",
      "False.\n",
      "\n",
      "The passage does not mention roasting asparagus or provide information on how long it takes to roast asparagus. It\n",
      "False.\n",
      "\n",
      "The passage does not provide information on how long to roast asparagus.\n",
      "TRUE\n",
      "\n",
      "The passage mentions that oven baking foil-wrapped asparagus takes between 12 and 20 minutes.\n",
      "Answer: TRUE\n",
      "\n",
      "(The passage provides information on roasting asparagus for 12-15 minutes, which directly answers the question.)\n",
      "False.\n",
      "\n",
      "The passage does not provide information on how long to roast asparagus.\n",
      "False.\n",
      "\n",
      "The passage does not provide specific cooking time for roasting asparagus. It only mentions that the cooking time depends on the method\n",
      "False.\n",
      "\n",
      "The passage does not mention how long to roast asparagus.\n",
      "FALSE\n",
      "FALSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:43<02:54, 43.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Answer: FALSE\n",
      "False.\n",
      "\n",
      "The passage states that the egg yolk is the part of an egg that feeds the developing embryo, but it does not say\n",
      "False.\n",
      "False. The egg yolk is not an embryo, but rather a source of food for the developing embryo.\n",
      "False.\n",
      "False.\n",
      "False.\n",
      "Answer: FALSE\n",
      "False. According to the passage, the egg yolk is used for the sustenance of the developing young (embryo), not that the egg y\n",
      "False. The egg yolk is not an embryo. It is a source of nutrition for the developing embryo.\n",
      "False.\n",
      "\n",
      "The passage mentions that after the egg cell is fertilized by male sperm, an embryo develops. However, it\n",
      "False.\n",
      "\n",
      "The passage states that the ovary contains undeveloped egg yolks, which are released into the oviduct as each yolk\n",
      "False\n",
      "False.\n",
      "\n",
      "The passage defines \"yolk\" as the part of an egg that enters directly into the formation of the embryo, along with any\n",
      "False. In the given passage, the yolk sac is where the food for the developing embryo comes from, and it reduces in size as the emb\n",
      "False. The passage does not suggest that the egg yolk is an embryo. Instead, it mentions the yolk sac, which is a structure\n",
      "False.\n",
      "\n",
      "The passage defines an egg as the mature reproductive cell of female animals, which carries half as many chromosomes as the other cells\n",
      "False. According to the passage, the yolk sac is a part of the human embryo, but it is not the embryo itself. The\n",
      "False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [01:25<02:07, 42.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "True.\n",
      "Answer: FALSE\n",
      "True.\n",
      "False.\n",
      "False.\n",
      "True.\n",
      "True. The passage provides a definition of non-renewable resources as resources that do not renew themselves at a sufficient rate for sustainable economic extraction in meaningful\n",
      "True.\n",
      "True.\n",
      "True. The passage provides a definition of non-renewable resources, which are resources that cannot be replenished or regenerated at a rate comparable to\n",
      "True.\n",
      "\n",
      "The passage defines non-renewable energy resources as energy resources that cannot sustain their consumption rate and will inevitably be empty if we continue\n",
      "True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [01:42<01:02, 31.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True.\n",
      "True.\n",
      "\n",
      "The passage mentions that \"Products may have a lower energy or higher energy than the reactants,\" indicating that there is a difference in\n",
      "True. The energy difference between reactants and products is a key aspect of chemical reactions. This energy difference can be in the form of heat energy, light energy\n",
      "True.\n",
      "\n",
      "The passage mentions that products in a chemical reaction may have a lower or higher energy than the reactants, indicating that there is a difference\n",
      "True.\n",
      "\n",
      "The passage mentions that during a chemical reaction, reactants undergo energy changes and break their chemical bonds to form new ones and generate products\n",
      "True. The energy difference between reactants and products in a chemical reaction is what determines whether a reaction is endothermic or exothermic. In an ex\n",
      "True\n",
      "True.\n",
      "True. The passage mentions that there can be energy changes when reactants are converted to products in a chemical reaction.\n",
      "FALSE\n",
      "\n",
      "The passage mentions that energy is released when a bond is formed, but it does not explicitly state that the energy difference between reactants and products\n",
      "False.\n",
      "\n",
      "The passage does not explicitly state that there is an energy difference between reactants and products in a chemical reaction. It only mentions that there\n",
      "True.\n",
      "\n",
      "The passage mentions that during a chemical reaction, energy changes occur as the chemical bonds in the reactants break and new bonds form to create\n",
      "TRUE\n",
      "\n",
      "The passage mentions that a chemical reaction involves breaking bonds (which requires energy) and making bonds (which releases energy). The difference in energy between\n",
      "True. The passage defines the difference between the potential energy of the products and the potential energy of the reactants as the \"heat of reaction,\" which is\n",
      "True.\n",
      "True. The energy difference between reactants and products in a chemical reaction is referred to as the enthalpy change of the reaction. In the given passage,\n",
      "False.\n",
      "\n",
      "The passage mentions that during a chemical reaction, there is an intermediate stage where chemical bonds are partially broken and partially formed. This implies that\n",
      "True. The energy difference between reactants and products in a chemical reaction is related to the passage. This concept is crucial to understanding exothermic and endother\n",
      "TRUE\n",
      "\n",
      "The passage mentions that it takes energy to break bonds in reactants (statement 3) and energy is released when bonds are formed in products\n",
      "False.\n",
      "\n",
      "The passage discusses the concept of activation energy and energy levels during a chemical reaction, but it does not mention the energy difference between reactants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [02:41<00:41, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False.\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University.\n",
      "False.\n",
      "Answer: FALSE\n",
      "Answer: TRUE\n",
      "\n",
      "The passage mentions that Kaplan University Davenport is located in Davenport, Iowa, which is a state in the Mid\n",
      "False.\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University.\n",
      "Answer: FALSE\n",
      "False.\n",
      "False.\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University. It is a review of an app, and the reviewer mentions\n",
      "False.\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University.\n",
      "False.\n",
      "Answer: FALSE\n",
      "False\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University.\n",
      "Answer: TRUE\n",
      "\n",
      "The passage mentions that Kaplan University has campuses in several states, including Iowa, Indiana, Nebraska, Missouri, Wisconsin\n",
      "Answer: TRUE\n",
      "\n",
      "The passage does not explicitly state the location of all Kaplan University campuses, but it does mention \"the five Iowa campuses,\"\n",
      "False.\n",
      "Answer: FALSE\n",
      "\n",
      "The passage does not provide information about the location or state where Kaplan University is located.\n",
      "False.\n",
      "\n",
      "The passage does not provide information about the location of Kaplan University.\n",
      "False.\n",
      "False.\n",
      "Answer: TRUE\n",
      "\n",
      "The passage mentions \"Kaplan University locations in Chattanooga, TN,\" which indicates that Kaplan University is located\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [03:15<00:00, 39.19s/it]\n"
     ]
    }
   ],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "for i in tqdm(data):\n",
    "    question = i['question']\n",
    "    passages = []\n",
    "    # we don't have to tag for gold knowledge segment (positive passage segment)\n",
    "    for j in i['positive_passage_segment']:\n",
    "        j['label']=True\n",
    "    for j in i['retrieved_passages']:\n",
    "        passages.append(get_passage_to_text(j))\n",
    "    relevances = []\n",
    "    for passage in passages:\n",
    "        prompt = knowledge_segment_relevance_tagging(tokenizer, passage, question)\n",
    "        inputs = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
    "        inputs = inputs.to(model.device)\n",
    "        length = inputs['input_ids'].size(1)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=32, streamer=streamer, pad_token_id=tokenizer.eos_token_id)\n",
    "        relevance = tokenizer.decode(outputs[0][length:], skip_special_tokens=True)\n",
    "        relevances.append(relevance)\n",
    "    for j,k in zip(i['retrieved_passages'],relevances):\n",
    "        j['label']=get_label(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8707346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qa_prompt(tokenizer, document, question, tokenize=False):\n",
    "    user_message = f\"\"\"Answer the question based on the given document.\n",
    "    Document : {document}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    messages = [\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=tokenize, \n",
    "            add_generation_prompt=True\n",
    "            )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ef9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_length_under(tokenizer, data_i, threshold):\n",
    "    gold_knowledge_segment = get_passage_to_text(data_i['positive_passage_segment'][0])\n",
    "    question = data_i['question']\n",
    "    basic_prompt = get_qa_prompt(tokenizer, gold_knowledge_segment, question, True)\n",
    "    prompt_length = len(basic_prompt)\n",
    "    selected_passages = [data_i['positive_passage_segment'][0]]\n",
    "    if prompt_length>=threshold:\n",
    "        return selected_passages\n",
    "    for i in data_i['retrieved_passages']:\n",
    "        passage_text = get_passage_to_text(i)\n",
    "        l = len(tokenizer.tokenize(passage_text+'\\n\\n'))\n",
    "        if prompt_length+l < threshold:\n",
    "            prompt_length += l\n",
    "            selected_passages.append(i)\n",
    "        elif prompt_length+l == threshold:\n",
    "            prompt_length += l\n",
    "            selected_passages.append(i)\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    # check\n",
    "    docs = '\\n\\n'.join([get_passage_to_text(i) for i in selected_passages]).strip()\n",
    "    prompt = get_qa_prompt(tokenizer, docs, data_i['question'], True)\n",
    "    if len(prompt)>threshold:\n",
    "        selected_passages.pop()\n",
    "    docs = '\\n\\n'.join([get_passage_to_text(i) for i in selected_passages]).strip()\n",
    "    prompt = get_qa_prompt(tokenizer, docs, data_i['question'], True)\n",
    "    assert len(prompt)<=threshold, tokenizer.decode(prompt)\n",
    "    return selected_passages, len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4c678",
   "metadata": {},
   "source": [
    "# chose prompt length and select passages for the length\n",
    "- because we use just 20 passages for our sample, all our data sample will be short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c560c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:00<00:00, 100.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(data):\n",
    "    threshold = random.sample([1024,2048,4096,8192],k=1)[0]\n",
    "    i['segments'],i['length'] = make_prompt_length_under(tokenizer, i, threshold)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb0a13",
   "metadata": {},
   "source": [
    "# Chosen Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "842a5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chosen_response_generation(tokenizer, context, question, tokenize=False):\n",
    "    user_message = f\"\"\"Answer the question based on the context.\n",
    "You SHOULD use all the information in the context to answer the question.\n",
    "SHOULD NOT say that you answered based on the given context.\n",
    "Context : {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "    messages = [\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=tokenize, \n",
    "            add_generation_prompt=True\n",
    "            )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8917d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should roast asparagus in the oven for 25 minutes at 400 degrees F, until it is tender but still crisp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:03<00:15,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the egg yolk is not an embryo. Although it is the part of an egg that would feed the embryo if an egg were fertilized, the egg yolk itself is not the embryo. The embryo would develop from the female's genetic material, which is contained in the egg's cytoplasm, and is not specifically the yolk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [00:13<00:21,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-renewable resource is a type of resource that cannot replenish or renew itself at a rate that matches its extraction and usage by humans. These resources are finite and become depleted as they are extracted and used. Examples of non-renewable resources include fossil fuels such as coal, oil, and natural gas, as well as minerals and metals. Once these resources are extracted, they cannot be replaced or regenerated within a human timeframe, making them unsustainable for long-term use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [00:25<00:19,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is (3) heat of reaction. The heat of reaction, also known as enthalpy change, is the difference in potential energy between the reactants and products in a chemical reaction. Activation energy is the energy required for a reaction to start, ionization energy is the energy required to remove an electron from an atom, and heat of vaporization is the energy required to change a substance from a liquid to a gas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [00:35<00:09,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaplan University is located in the state of Iowa, as its main campus is in Davenport. However, it's important to note that Kaplan University also has a significant presence in other states, including Nebraska, Maryland, Florida, and Illinois. The main administration building is located in Fort Lauderdale, Florida, and there are additional campuses and learning centers in these states as well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:45<00:00,  9.08s/it]\n"
     ]
    }
   ],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "for i in tqdm(data):\n",
    "    question = i['question']\n",
    "    context = i['segments']\n",
    "    context = '\\n\\n'.join([get_passage_to_text(j) for j in context if j['label']==True]).strip()\n",
    "    prompt = chosen_response_generation(tokenizer, context, question)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
    "    inputs = inputs.to(model.device)\n",
    "    length = inputs['input_ids'].size(1)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=2048, streamer=streamer, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0][length:], skip_special_tokens=True)\n",
    "    i['chosen']=copy.deepcopy(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c1c6e",
   "metadata": {},
   "source": [
    "# Rejected Response Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f13d75",
   "metadata": {},
   "source": [
    "## Partial Evidence-Based response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e49d6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should roast asparagus for 25 minutes in an oven preheated to 400 degrees F.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:03<00:12,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the egg yolk is not an embryo. It is the part of an egg that can potentially nourish an embryo with its high fat, protein, vitamin, and mineral content. The egg yolk is a major source of nutrition for the embryo if the egg is fertilized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [00:10<00:17,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-renewable resource is defined as a resource that does not renew itself at a rate sufficient for sustainable economic extraction in meaningful human time-frames. This means that once used, these resources cannot be replenished or regenerated within a humanly relevant time period. An example of a non-renewable resource is coal, which is produced over millions of years, and carbon-based, organically-derived fuels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [00:21<00:15,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is the heat of reaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [00:21<00:05,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaplan University is located in multiple states. The main administration building is in Fort Lauderdale, Florida. The university also has physical campuses in Iowa, Nebraska, and Maryland, and online student support centers in Florida and Illinois.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:27<00:00,  5.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(data):\n",
    "    question = i['question']\n",
    "    context = i['segments']\n",
    "    context = [get_passage_to_text(j) for j in context if j['label']==True]\n",
    "    context = random.sample(context, k=1)\n",
    "    prompt = chosen_response_generation(tokenizer, context, question)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
    "    inputs = inputs.to(model.device)\n",
    "    length = inputs['input_ids'].size(1)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=2048, streamer=streamer, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0][length:], skip_special_tokens=True)\n",
    "    i['partial_evidence_based_response']=copy.deepcopy(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adee7e3",
   "metadata": {},
   "source": [
    "# Distorted evidence-Based response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd31527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distorted_evidence_based_response(tokenizer, context, question, tokenize=False):\n",
    "    user_message = f\"\"\"The Given context is UNRELATED to the question.\n",
    "    Make WRONG answer to the question based on the UNRELATED context.\n",
    "    SHOULD NOT say that you answered based on the given context.\n",
    "    UNRELATED Context : {context}\n",
    "    Question: {question}\n",
    "    WRONG Answer:\"\"\"\n",
    "    messages = [\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=tokenize, \n",
    "            add_generation_prompt=True\n",
    "            )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9094074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, which is a recipe for roasting asparagus, one might assume that asparagus should be roasted for the length of time specified in the recipe. However, the question specifically asks how long to roast asparagus, not how long it is roasted in this particular recipe.\n",
      "\n",
      "Therefore, a wrong answer to the question could be: \"You should roast asparagus for 30 minutes.\" This answer is wrong because it contradicts the recipe provided in the given context, which specifies a roasting time of 25 minutes. However, it is important to note that this answer is not wrong because it is based on the given context, but rather because it is incorrect in general.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:17<01:10, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the egg yolk is not an embryo. It is the part of an egg that feeds the embryo and contains a high concentration of fat, protein, vitamins, and minerals. It is a major source of nutrition for the developing embryo, but it is not the embryo itself. The embryo is formed from the fertilized egg and develops in the egg white, or albumen, not in the yolk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [00:28<00:41, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-renewable resource is a type of resource that, once used, cannot be replaced or reproduced in a short period of time. This includes resources like coal, which are produced over millions of years and are not able to be replenished at a rate that is sustainable for human use. An example of a non-renewable resource is a mineral deposit, which cannot be replaced once it has been extracted and used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [00:38<00:24, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The energy difference between reactants and products in a chemical reaction is called the heat of vaporization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [00:41<00:08,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, Kaplan University is not located in just one state. The main administration building is in Florida, but the university also has campuses in Iowa, Nebraska, and Maryland. Therefore, it would be incorrect to say that Kaplan University is located in only one state. However, to provide a wrong answer that is unrelated to the context, let's say that Kaplan University is located in California.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:51<00:00, 10.31s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(data):\n",
    "    question = i['question']\n",
    "    context = i['segments']\n",
    "    context = [get_passage_to_text(j) for j in context if j['label']==True]\n",
    "    context = random.sample(context, k=1)\n",
    "    prompt = get_distorted_evidence_based_response(tokenizer, context, question)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
    "    inputs = inputs.to(model.device)\n",
    "    length = inputs['input_ids'].size(1)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=2048, streamer=streamer, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0][length:], skip_special_tokens=True)\n",
    "    i['distorted_evidence_based_response']=copy.deepcopy(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27441393",
   "metadata": {},
   "source": [
    "# make 50:50 for rejected response and make dataset for DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62eb9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_path = 'meta-llama/Meta-Llama-3-8B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "653ed80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483cc67f4e7f48daa78f88fa709c9495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e43abe241a483096baa29175a5069a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d0b5f1f15544dfab5809d1c66bc284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3520b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3043ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_train = []\n",
    "for i in data:\n",
    "    context = [get_passage_to_text(j) for j in i['segments']]\n",
    "    random.shuffle(context)\n",
    "    context = '\\n\\n'.join(context)\n",
    "    question = i['question']\n",
    "    input = get_qa_prompt(tokenizer, context, question)\n",
    "    tmp = dict()\n",
    "    tmp['input']=input\n",
    "    tmp['chosen']=i['chosen']\n",
    "    tmp['passages']=copy.deepcopy(i['segments'])\n",
    "    rejected = random.sample([i['partial_evidence_based_response'],i['distorted_evidence_based_response']],k=1)[0]\n",
    "    tmp['rejected']=rejected\n",
    "    dpo_train.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8e3ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:00<00:00, 5717.43it/s]\n"
     ]
    }
   ],
   "source": [
    "save_jsonl('.',dpo_train,'dpo_train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
